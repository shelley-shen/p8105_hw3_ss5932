Homework 3
================
Shelley Shen
10/6/2020

## Problem 1

Load Instacart data.

``` r
data("instacart")
```

This dataset contains 1384617 rows and 15 columns.

Observations are the level of items in orders by user. There are user /
order variables – user ID, oder ID, order day, and order hour. There are
also item variables == name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ... with 124 more rows

Let’s make a plot of the number of items ordered in each aisle, limited
to those aisles with \>10,000 items ordered.

``` r
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_ss5932_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

Make a table of most popular items in each aisle of interest: baking
ingredients, dog food, packaged vegetables fruits.

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Make table for mean hour of day when Pink Lady Apples and Coffee Ice
Cream are ordered on each day of the week

``` r
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

## Problem 2

Load in the accelerometer data and tidy.

``` r
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count") %>% 
  group_by(day) %>% 
  mutate(
    minute = as.numeric(minute), 
    day = as.factor(day),
    activity_count = as.numeric(activity_count),
    day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")),
    weekday = if_else(day %in% c("Saturday", "Sunday"), "Weekend", "Weekday"))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

    ## Warning: Problem with `mutate()` input `day`.
    ## i Unknown levels in `f`: Sunday, Monday, Tuesday, Wednesday, Thursday, Saturday
    ## i Input `day` is `forcats::fct_relevel(...)`.
    ## i The error occurred in group 1: day = "Friday".

    ## Warning: Unknown levels in `f`: Sunday, Monday, Tuesday, Wednesday, Thursday,
    ## Saturday

    ## Warning: Problem with `mutate()` input `day`.
    ## i Unknown levels in `f`: Sunday, Tuesday, Wednesday, Thursday, Friday, Saturday
    ## i Input `day` is `forcats::fct_relevel(...)`.
    ## i The error occurred in group 2: day = "Monday".

    ## Warning: Unknown levels in `f`: Sunday, Tuesday, Wednesday, Thursday, Friday,
    ## Saturday

    ## Warning: Problem with `mutate()` input `day`.
    ## i Unknown levels in `f`: Sunday, Monday, Tuesday, Wednesday, Thursday, Friday
    ## i Input `day` is `forcats::fct_relevel(...)`.
    ## i The error occurred in group 3: day = "Saturday".

    ## Warning: Unknown levels in `f`: Sunday, Monday, Tuesday, Wednesday, Thursday,
    ## Friday

    ## Warning: Problem with `mutate()` input `day`.
    ## i Unknown levels in `f`: Monday, Tuesday, Wednesday, Thursday, Friday, Saturday
    ## i Input `day` is `forcats::fct_relevel(...)`.
    ## i The error occurred in group 4: day = "Sunday".

    ## Warning: Unknown levels in `f`: Monday, Tuesday, Wednesday, Thursday, Friday,
    ## Saturday

    ## Warning: Problem with `mutate()` input `day`.
    ## i Unknown levels in `f`: Sunday, Monday, Tuesday, Wednesday, Friday, Saturday
    ## i Input `day` is `forcats::fct_relevel(...)`.
    ## i The error occurred in group 5: day = "Thursday".

    ## Warning: Unknown levels in `f`: Sunday, Monday, Tuesday, Wednesday, Friday,
    ## Saturday

    ## Warning: Problem with `mutate()` input `day`.
    ## i Unknown levels in `f`: Sunday, Monday, Wednesday, Thursday, Friday, Saturday
    ## i Input `day` is `forcats::fct_relevel(...)`.
    ## i The error occurred in group 6: day = "Tuesday".

    ## Warning: Unknown levels in `f`: Sunday, Monday, Wednesday, Thursday, Friday,
    ## Saturday

    ## Warning: Problem with `mutate()` input `day`.
    ## i Unknown levels in `f`: Sunday, Monday, Tuesday, Thursday, Friday, Saturday
    ## i Input `day` is `forcats::fct_relevel(...)`.
    ## i The error occurred in group 7: day = "Wednesday".

    ## Warning: Unknown levels in `f`: Sunday, Monday, Tuesday, Thursday, Friday,
    ## Saturday

**Part 1** - tidy using pivot long –\> columns are week, day of week,
minute of day, and activity count. - mutate for weekday vs. weekend

**Part 2**

  - aggregate activity for total day –\> group\_by week, day and
    summarize –\> 35 days –\> week \# and day of week
  - trends inherent: more activity during certain day, etc.

**Part 3** - single panel plot: x = minute, y = activity count –\>
scatterplot with geom\_line, color to indicate day of week, trends

Potential issues: - day of week by default in alphabetical order –\> use
factors to order how we want - when pivot\_longer, need to check if
minute is in numeric format or some other format so the plot will make
sense when merged

## Problem 3

``` r
data("ny_noaa")
```

**Part 1** - separate date variable into month, day, year - make sure
unit is reasonable based on data dictionary - need to count and rank

**Part 2** - need to group so avg max temp separately in Jan and in July
–\> use group\_by and summarize - group by station, year, month, then
summarize avg max temp, filter - y = station, x = years

**Part 3** - make 2 plots and merge together - 1) contour plot, bin
plot, or hex plot - 2) filter, show distribution (fox plot, violin,
ridge – one ridge per year)
